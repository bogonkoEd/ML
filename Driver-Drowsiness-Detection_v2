{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3667213,"sourceType":"datasetVersion","datasetId":2195166}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.multiprocessing as mp\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms, models\nimport numpy as np\nfrom pathlib import Path\nimport time\nimport cv2\nimport os\n\n# Check GPU availability\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\nprint(f\"Number of GPUs available: {torch.cuda.device_count()}\")\nif torch.cuda.is_available():\n    print(f\"GPU Model: {torch.cuda.get_device_name(0)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:17:06.531368Z","iopub.execute_input":"2024-11-05T06:17:06.531810Z","iopub.status.idle":"2024-11-05T06:17:06.541365Z","shell.execute_reply.started":"2024-11-05T06:17:06.531755Z","shell.execute_reply":"2024-11-05T06:17:06.540297Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nNumber of GPUs available: 2\nGPU Model: Tesla T4\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"class Config:\n    \"\"\"Configuration class to manage all hyperparameters and settings\"\"\"\n    def __init__(self):\n        # Dataset\n        self.DATA_ROOT = '/kaggle/input/driver-drowsiness-dataset-ddd/Driver Drowsiness Dataset (DDD)'\n        self.IMAGE_SIZE = 640\n        self.BATCH_SIZE = 32\n        self.NUM_WORKERS = 4\n        \n        # Training\n        self.EPOCHS = 100\n        self.LEARNING_RATE = 1e-3\n        self.WEIGHT_DECAY = 1e-4\n        \n        # Model\n        self.PRETRAINED = True\n        \n        # Checkpoints\n        self.CHECKPOINT_DIR = './checkpoints'\n        Path(self.CHECKPOINT_DIR).mkdir(exist_ok=True)\n        \n        # Device\n        self.DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        \n        # Data Transforms\n        self.train_transform = transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((self.IMAGE_SIZE, self.IMAGE_SIZE)),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomRotation(10),\n            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                              std=[0.229, 0.224, 0.225])\n        ])\n        \n        self.val_transform = transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.Resize((self.IMAGE_SIZE, self.IMAGE_SIZE)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n                              std=[0.229, 0.224, 0.225])\n        ])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:17:06.546441Z","iopub.execute_input":"2024-11-05T06:17:06.547116Z","iopub.status.idle":"2024-11-05T06:17:06.557806Z","shell.execute_reply.started":"2024-11-05T06:17:06.547079Z","shell.execute_reply":"2024-11-05T06:17:06.556729Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"# Eye Detection and PERCLOS Calculation\ndef detect_eyes(image):\n    \"\"\"Detect eyes in the image using YOLOv5\"\"\"\n    model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n    model.classes = [0]  # Only detect eyes\n    \n    results = model(image)\n    boxes = results.xyxy[0].cpu().numpy()\n    \n    eye_boxes = []\n    for box in boxes:\n        x1, y1, x2, y2 = box[:4]\n        w = x2 - x1\n        h = y2 - y1\n        eye_boxes.append([x1, y1, w, h])\n    \n    if len(eye_boxes) == 0:\n        h, w = image.shape[:2]\n        return [w/4, h/4, w/2, h/2]\n    \n    return eye_boxes[0]\n\ndef calculate_ear(eye_region):\n    \"\"\"Calculate Eye Aspect Ratio (EAR)\"\"\"\n    contours, _ = cv2.findContours(eye_region, cv2.RETR_EXTERNAL, \n                                 cv2.CHAIN_APPROX_SIMPLE)\n    \n    if not contours:\n        return 0.0\n    \n    eye_contour = max(contours, key=cv2.contourArea)\n    x, y, w, h = cv2.boundingRect(eye_contour)\n    \n    ear = float(h) / float(w) if w > 0 else 0.0\n    normalized_ear = min(max(ear - 0.2, 0) / 0.3, 1)\n    \n    return normalized_ear\n\ndef calculate_perclos(image, bbox):\n    \"\"\"Calculate PERCLOS (PERcentage of eye CLOSure)\"\"\"\n    x, y, w, h = [int(v) for v in bbox]\n    eye_region = image[y:y+h, x:x+w]\n    \n    if eye_region.size == 0:\n        return 0.5\n    \n    gray = cv2.cvtColor(eye_region, cv2.COLOR_RGB2GRAY)\n    _, thresh = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)\n    \n    ear = calculate_ear(thresh)\n    perclos = 1.0 - min(max(ear, 0), 1)\n    \n    return perclos","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:17:06.559519Z","iopub.execute_input":"2024-11-05T06:17:06.559911Z","iopub.status.idle":"2024-11-05T06:17:06.572973Z","shell.execute_reply.started":"2024-11-05T06:17:06.559856Z","shell.execute_reply":"2024-11-05T06:17:06.572195Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"class DrowsinessDataset(Dataset):\n    \"\"\"Dataset class for drowsiness detection\"\"\"\n    def __init__(self, root_dir, transform=None, train=True):\n        self.root_dir = root_dir\n        self.transform = transform\n        self.train = train\n        self.data = self._load_data()\n    \n    def _load_data(self):\n        data = []\n        for label in ['Drowsy', 'Non Drowsy']:\n            label_dir = os.path.join(self.root_dir, label)\n            for img_name in os.listdir(label_dir):\n                data.append({\n                    'path': os.path.join(label_dir, img_name),\n                    'label': 1 if label == 'Drowsy' else 0\n                })\n        \n        split_idx = int(len(data) * 0.8)\n        return data[split_idx:] if not self.train else data[:split_idx]\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img_info = self.data[idx]\n        image = cv2.imread(img_info['path'])\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        eyes_bbox = detect_eyes(image)\n        perclos = calculate_perclos(image, eyes_bbox)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return {\n            'image': image,\n            'label': torch.tensor(img_info['label'], dtype=torch.long),\n            'bbox': torch.tensor(eyes_bbox, dtype=torch.float32),\n            'perclos': torch.tensor(perclos, dtype=torch.float32)\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:17:06.574144Z","iopub.execute_input":"2024-11-05T06:17:06.574462Z","iopub.status.idle":"2024-11-05T06:17:06.585947Z","shell.execute_reply.started":"2024-11-05T06:17:06.574431Z","shell.execute_reply":"2024-11-05T06:17:06.585146Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"class DrowsinessModel(nn.Module):\n    \"\"\"Model architecture for drowsiness detection\"\"\"\n    def __init__(self, pretrained=True):\n        super(DrowsinessModel, self).__init__()\n        self.yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n        self.yolo.classes = [0]\n        \n        self.backbone = models.resnet50(pretrained=pretrained)\n        num_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Identity()\n        \n        self.detection_head = nn.Sequential(\n            nn.Linear(num_features, 512),\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(512, 2)\n        )\n        \n        self.perclos_head = nn.Sequential(\n            nn.Linear(num_features, 256),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(256, 1),\n            nn.Sigmoid()\n        )\n        \n        self._freeze_layers()\n    \n    def _freeze_layers(self):\n        \"\"\"Freeze early layers of the backbone\"\"\"\n        for param in self.yolo.parameters():\n            param.requires_grad = False\n        \n        layers_to_freeze = [self.backbone.conv1, self.backbone.bn1,\n                          self.backbone.layer1, self.backbone.layer2]\n        for layer in layers_to_freeze:\n            for param in layer.parameters():\n                param.requires_grad = False\n    \n    def forward(self, x):\n        features = self.backbone(x)\n        detection = self.detection_head(features)\n        perclos = self.perclos_head(features)\n        return detection, perclos","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:17:06.587911Z","iopub.execute_input":"2024-11-05T06:17:06.588286Z","iopub.status.idle":"2024-11-05T06:17:06.599064Z","shell.execute_reply.started":"2024-11-05T06:17:06.588242Z","shell.execute_reply":"2024-11-05T06:17:06.598138Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"class DrowsinessLoss(nn.Module):\n    \"\"\"Combined loss function for drowsiness detection\"\"\"\n    def __init__(self):\n        super(DrowsinessLoss, self).__init__()\n        self.classification_loss = nn.CrossEntropyLoss()\n        self.perclos_loss = nn.MSELoss()\n    \n    def forward(self, predictions, targets):\n        det_outputs, perclos_outputs = predictions\n        det_loss = self.classification_loss(det_outputs, targets['labels'])\n        perclos_loss = self.perclos_loss(perclos_outputs, targets['perclos'])\n        \n        total_loss = det_loss * 0.7 + perclos_loss * 0.3\n        \n        return total_loss, {\n            'det_loss': det_loss.item(),\n            'perclos_loss': perclos_loss.item()\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:17:06.633389Z","iopub.execute_input":"2024-11-05T06:17:06.633709Z","iopub.status.idle":"2024-11-05T06:17:06.640547Z","shell.execute_reply.started":"2024-11-05T06:17:06.633677Z","shell.execute_reply":"2024-11-05T06:17:06.639600Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"def plot_metrics(train_losses, val_losses, accuracies):\n    \"\"\"Plot training metrics\"\"\"\n    plt.figure(figsize=(15, 5))\n    \n    plt.subplot(1, 2, 1)\n    plt.plot(train_losses, label='Train Loss')\n    plt.plot(val_losses, label='Val Loss')\n    plt.title('Losses over epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(accuracies, label='Validation Accuracy')\n    plt.title('Accuracy over epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Accuracy (%)')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\ndef save_checkpoint(model, optimizer, epoch, accuracy, filename):\n    \"\"\"Save model checkpoint\"\"\"\n    checkpoint = {\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'accuracy': accuracy,\n    }\n    torch.save(checkpoint, filename)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:17:06.642341Z","iopub.execute_input":"2024-11-05T06:17:06.642685Z","iopub.status.idle":"2024-11-05T06:17:06.651647Z","shell.execute_reply.started":"2024-11-05T06:17:06.642654Z","shell.execute_reply":"2024-11-05T06:17:06.650732Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"def validate(model, val_loader, loss_fn, device):\n    \"\"\"Validation function\"\"\"\n    model.eval()\n    total_loss = 0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            images = batch['image'].to(device)\n            labels = batch['label'].to(device)\n            bboxes = batch['bbox'].to(device)\n            perclos = batch['perclos'].to(device)\n            \n            det_outputs, perclos_outputs = model(images)\n            loss, _ = loss_fn((det_outputs, perclos_outputs),\n                            {'boxes': bboxes, 'labels': labels, 'perclos': perclos})\n            \n            _, predicted = torch.max(det_outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            total_loss += loss.item()\n    \n    accuracy = 100 * correct / total\n    avg_loss = total_loss / len(val_loader)\n    return avg_loss, accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:17:06.653473Z","iopub.execute_input":"2024-11-05T06:17:06.653925Z","iopub.status.idle":"2024-11-05T06:17:06.663038Z","shell.execute_reply.started":"2024-11-05T06:17:06.653881Z","shell.execute_reply":"2024-11-05T06:17:06.662146Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"def train(model, train_loader, val_loader, loss_fn, optimizer, scheduler, config):\n    \"\"\"Main training loop\"\"\"\n    best_accuracy = 0\n    train_losses = []\n    val_losses = []\n    accuracies = []\n    device = config.DEVICE\n    \n    print(f\"Training on {device}\")\n    print(f\"Number of GPUs available: {torch.cuda.device_count()}\")\n    if torch.cuda.is_available():\n        print(f\"GPU Model: {torch.cuda.get_device_name(0)}\")\n    \n    for epoch in range(config.EPOCHS):\n        start_time = time.time()\n        print(f\"\\nEpoch {epoch+1}/{config.EPOCHS}\")\n        \n        # Training phase\n        model.train()\n        epoch_loss = 0\n        train_steps = 0\n        \n        for batch in train_loader:\n            images = batch['image'].to(device)\n            labels = batch['label'].to(device)\n            bboxes = batch['bbox'].to(device)\n            perclos = batch['perclos'].to(device)\n            \n            optimizer.zero_grad()\n            det_outputs, perclos_outputs = model(images)\n            \n            loss, loss_components = loss_fn(\n                (det_outputs, perclos_outputs),\n                {'boxes': bboxes, 'labels': labels, 'perclos': perclos}\n            )\n            \n            loss.backward()\n            optimizer.step()\n            \n            epoch_loss += loss.item()\n            train_steps += 1\n            \n            if train_steps % 10 == 0:\n                print(f\"Step {train_steps}/{len(train_loader)}: \"\n                      f\"Loss = {loss.item():.4f}, \"\n                      f\"Det Loss = {loss_components['det_loss']:.4f}, \"\n                      f\"PERCLOS Loss = {loss_components['perclos_loss']:.4f}\")\n        \n        avg_train_loss = epoch_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        \n        # Validation phase\n        val_loss, accuracy = validate(model, val_loader, loss_fn, device)\n        val_losses.append(val_loss)\n        accuracies.append(accuracy)\n        \n        scheduler.step(val_loss)\n        \n        if accuracy > best_accuracy:\n            best_accuracy = accuracy\n            save_checkpoint(\n                model, optimizer, epoch, accuracy,\n                f\"{config.CHECKPOINT_DIR}/best_model.pth\"\n            )\n        \n        if (epoch + 1) % 10 == 0:\n            save_checkpoint(\n                model, optimizer, epoch, accuracy,\n                f\"{config.CHECKPOINT_DIR}/checkpoint_epoch_{epoch+1}.pth\"\n            )\n        \n        epoch_time = time.time() - start_time\n        print(f\"Epoch {epoch+1} completed in {epoch_time:.2f}s\")\n        print(f\"Train Loss: {avg_train_loss:.4f}\")\n        print(f\"Val Loss: {val_loss:.4f}\")\n        print(f\"Accuracy: {accuracy:.2f}%\")\n        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n        \n        if (epoch + 1) % 5 == 0:\n            plot_metrics(train_losses, val_losses, accuracies)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:17:06.664463Z","iopub.execute_input":"2024-11-05T06:17:06.664761Z","iopub.status.idle":"2024-11-05T06:17:06.678645Z","shell.execute_reply.started":"2024-11-05T06:17:06.664712Z","shell.execute_reply":"2024-11-05T06:17:06.677791Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    mp.set_start_method('spawn', force=True)\n    \n    # Initialize config\n    config = Config()\n    \n    # Create datasets and dataloaders\n    train_dataset = DrowsinessDataset(\n        root_dir=config.DATA_ROOT,\n        transform=config.train_transform,\n        train=True\n    )\n    val_dataset = DrowsinessDataset(\n        root_dir=config.DATA_ROOT,\n        transform=config.val_transform,\n        train=False\n    )\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config.BATCH_SIZE,\n        shuffle=True,\n        num_workers=config.NUM_WORKERS,\n        pin_memory=True\n    )\n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config.BATCH_SIZE,\n        shuffle=False,\n        num_workers=config.NUM_WORKERS,\n        pin_memory=True\n    )\n    \n    print(f\"Training samples: {len(train_dataset)}\")\n    print(f\"Validation samples: {len(val_dataset)}\")\n    \n    # Initialize model\n    model = DrowsinessModel(pretrained=config.PRETRAINED).to(config.DEVICE)\n    \n    # Initialize loss function\n    loss_fn = DrowsinessLoss()\n    \n    # Initialize optimizer\n    optimizer = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE, weight_decay=config.WEIGHT_DECAY)\n    \n    # Initialize learning rate scheduler\n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5, verbose=True)\n    \n    # Start training\n    train(model, train_loader, val_loader, loss_fn, optimizer, scheduler, config)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-05T06:20:29.536804Z","iopub.execute_input":"2024-11-05T06:20:29.537194Z"}},"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\nYOLOv5 🚀 2024-11-5 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n\n","output_type":"stream"},{"name":"stdout","text":"Training samples: 33434\nValidation samples: 8359\n","output_type":"stream"},{"name":"stderr","text":"Fusing layers... \nYOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\nAdding AutoShape... \n","output_type":"stream"},{"name":"stdout","text":"Training on cuda\nNumber of GPUs available: 2\nGPU Model: Tesla T4\n\nEpoch 1/100\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/opt/conda/lib/python3.10/multiprocessing/spawn.py\", line 116, in spawn_main\n    exitcode = _main(fd, parent_sentinel)\n  File \"/opt/conda/lib/python3.10/multiprocessing/spawn.py\", line 126, in _main\n    self = reduction.pickle.load(from_parent)\nAttributeError: Can't get attribute 'DrowsinessDataset' on <module '__main__' (built-in)>\n","output_type":"stream"}],"execution_count":null}]}